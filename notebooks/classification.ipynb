{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d395b574-529c-4548-96dc-c7a33e2444b5",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this notebook we will examine classification success of 16S data collected and analyzed in the Nextflow QIIME2 Pipeline\n",
    "\n",
    "First, we will collect study IDs, stratified by URT collection area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ab3b6-b0a2-4c88-8b4e-73b0c52c1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f46e2a-caa6-4379-9c88-d62dd51369fd",
   "metadata": {},
   "source": [
    "## Gather QIIME2 artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db088c-0e29-4bab-961b-b96fe310370a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids_NP = glob.glob(\"../data/NP/*_taxonomy.qza\")\n",
    "ids_NP = [i.split(\"_\")[0].split(\"/\")[-1] for i in ids_NP]\n",
    "ids_OP = glob.glob(\"../data/OP/*_taxonomy.qza\")\n",
    "ids_OP = [i.split(\"_\")[0].split(\"/\")[-1] for i in ids_OP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905b08f-5481-4974-bb8c-284f83538899",
   "metadata": {},
   "source": [
    "Now we walk through and read the abundance and format everything nicely to a long DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a0981-aaf4-4573-beb6-b643bc3bc75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rich.progress import track\n",
    "from plotnine import *\n",
    "from utils import qiime_to_dataframe\n",
    "\n",
    "path_NP = \"../data/NP\"\n",
    "path_OP = \"../data/OP\"\n",
    "\n",
    "\n",
    "data_NP = []\n",
    "data_OP = []\n",
    "\n",
    "for pid_NP in track(ids_NP):\n",
    "    df = qiime_to_dataframe(f\"{path_NP}/{pid_NP}_table.qza\", f\"{path_NP}/{pid_NP}_taxonomy.qza\")\n",
    "    df[\"study\"] = pid_NP\n",
    "    df[\"urt\"] = 'Nasopharynx'\n",
    "    data_NP.append(df)\n",
    "    \n",
    "for pid_OP in track(ids_OP):\n",
    "    df = qiime_to_dataframe(f\"{path_OP}/{pid_OP}_table.qza\", f\"{path_OP}/{pid_OP}_taxonomy.qza\")\n",
    "    df[\"study\"] = pid_OP\n",
    "    df[\"urt\"] = 'Oropharynx'\n",
    "    data_OP.append(df)\n",
    "\n",
    "data_NP = pd.concat(data_NP)\n",
    "data_OP = pd.concat(data_OP)\n",
    "data = data_NP.append(data_OP,ignore_index = True)\n",
    "data['study'] = data['study'].str.replace('PRJEB15534','PRJEB22676')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870cc69d-5745-4b9c-973e-3f446c520064",
   "metadata": {},
   "source": [
    "## Classification Percentage\n",
    "Now, we'll take a look at overall classification percentage for each taxonomic level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adde6c-ad94-4516-8090-ce5759bb7bad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.loc[data.kingdom == \"Unassigned\", \"kingdom\"] = None\n",
    "ranks = [\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"]\n",
    "cl = pd.Series()\n",
    "for r in ranks:\n",
    "    cl[r] = data[data[r].notnull()].reads.sum() / data.reads.sum()\n",
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b9fa3-4c00-4132-a850-d07772a596ec",
   "metadata": {},
   "source": [
    "## Classification Dataframe\n",
    "Let's put together a dataframe of classification percentage for each study, at each taxonomic level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-opening",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# initialize dataframe\n",
    "classification = pd.DataFrame({'study':[]})\n",
    "for study in data['study'].unique():\n",
    "    \n",
    "    total_reads = data[data['study'].str.contains(study)]['reads'].sum()\n",
    "    \n",
    "    # calculate not-null reads divided by total reads in given study at each rank\n",
    "    classified_reads_species = data[(data['study'].str.contains(study))&\n",
    "        (data['species'].notnull())]['reads'].sum()/data[data['study'].str.contains(study)]['reads'].sum()\n",
    "    \n",
    "    classified_reads_genus = data[(data['study'].str.contains(study))&\n",
    "        (data['genus'].notnull())]['reads'].sum()/data[data['study'].str.contains(study)]['reads'].sum()\n",
    "    \n",
    "    classified_reads_family = data[(data['study'].str.contains(study))&\n",
    "        (data['family'].notnull())]['reads'].sum()/data[data['study'].str.contains(study)]['reads'].sum()\n",
    "    \n",
    "    classified_reads_order = data[(data['study'].str.contains(study))&\n",
    "        (data['order'].notnull())]['reads'].sum()/data[data['study'].str.contains(study)]['reads'].sum()\n",
    "    \n",
    "    classified_reads_class = data[(data['study'].str.contains(study))&\n",
    "        (data['class'].notnull())]['reads'].sum()/data[data['study'].str.contains(study)]['reads'].sum()\n",
    "    \n",
    "    classified_reads_phylum = data[(data['study'].str.contains(study))&\n",
    "        (data['phylum'].notnull())]['reads'].sum()/data[data['study'].str.contains(study)]['reads'].sum()\n",
    "    \n",
    "    classification = pd.concat([classification, pd.DataFrame({\n",
    "        'study':[study],\n",
    "        'species':[classified_reads_species],\n",
    "        'genus':[classified_reads_genus],\n",
    "        'family':[classified_reads_family],\n",
    "        'order':[classified_reads_order],\n",
    "        'class':[classified_reads_class],\n",
    "        'phylum':[classified_reads_phylum]})\n",
    "                               ])\n",
    "# format dataframe \n",
    "classification = classification[['study','phylum','class','order','family','genus','species']].set_index('study')\n",
    "classification = classification*100\n",
    "\n",
    "# add disease conditions to dataframe\n",
    "disease = pd.read_csv('../data/studies.csv', header = None, index_col = 0)[2].to_dict()\n",
    "classification['disease'] = classification.index.map(disease)\n",
    "\n",
    "classification = classification.sort_values(by = 'disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69652e2-2aed-4484-b256-369862787d96",
   "metadata": {},
   "source": [
    "## Plot Classification \n",
    "Now we'll plot the classification percentage for each study at each level on a heatmap, using Seaborn. We'll add a color bar signifying disease type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-summary",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "palette = sns.color_palette(\"Paired\", 11)\n",
    "lut = dict(zip(classification['disease'].unique(),palette))\n",
    "row_colors = classification['disease'].map(lut)\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "ax = sns.clustermap(classification[['phylum','class','order','family','genus','species']],vmin = 0, \n",
    "                    vmax = 100, row_colors=row_colors,row_cluster = False,col_cluster = False,\n",
    "                    cbar_pos=[1,0.1,.1,.7],cbar_kws={'label':'Percent Classified'})\n",
    "\n",
    "for label in classification['disease'].unique():\n",
    "    ax.ax_col_dendrogram.bar(0, 0, color=lut[label],\n",
    "                            label=label, linewidth=0)\n",
    "ax.ax_col_dendrogram.legend(loc=\"center\", ncol=5)\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b782d-1124-45af-9504-c52147c09ddf",
   "metadata": {},
   "source": [
    "## Phyla Distribution\n",
    "That looks good! Let's look at the phyla distributions on a heatmap. Again we'll use seaborn, and plot phylum abundance for each sample across all studies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fc504-f646-484f-8351-ff77f91bce6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#pivot data table to phylum abundances \n",
    "mat = pd.pivot_table(\n",
    "    data[(data.kingdom == \"Bacteria\") & data.genus.notnull()], \n",
    "    index=\"sample_id\", \n",
    "    values=\"reads\", \n",
    "    columns=\"phylum\", \n",
    "    aggfunc=sum, \n",
    "    fill_value=0.0\n",
    ")\n",
    "\n",
    "mat = mat[mat.columns[mat.mean(axis=0) > 5]]\n",
    "study_dict = data.set_index('sample_id')['study'].to_dict()\n",
    "mat['study'] = mat.index.map(study_dict)\n",
    "mat['disease'] = mat['study'].map(disease)\n",
    "mat = mat.sort_values(by = 'disease')\n",
    "\n",
    "lut = dict(zip(mat['disease'].unique(),palette))\n",
    "row_colors = mat['disease'].map(lut)\n",
    "sns.set(font_scale=2.4)\n",
    "x = sns.clustermap(np.log10(mat.iloc[:,:-2].T+0.5), yticklabels=True, \n",
    "                   col_colors = row_colors, col_cluster = False, xticklabels=False, \n",
    "                   cbar_pos=[1,0.025,.05,.75],figsize=(30, 15), cbar_kws={'label':'Sequence Reads (Log Scale)'})\n",
    "\n",
    "for label in mat['disease'].unique():\n",
    "    x.ax_col_dendrogram.bar(0, 0, color=lut[label],\n",
    "                            label=label, linewidth=0)\n",
    "x.ax_col_dendrogram.legend(loc=\"center\", ncol=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
