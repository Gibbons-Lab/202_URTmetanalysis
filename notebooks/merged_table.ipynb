{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0aa766-0d13-49b7-ba1b-6db6e697d78b",
   "metadata": {},
   "source": [
    "# Build Merged Table\n",
    "To begin our analysis, we'll build a merged table of reads, that we'll use for most of the following analyses. This will collect all data from the data directory, and build a table with all reads, annotated with metadata. \n",
    "\n",
    "\n",
    "To ensure the following cells work properly, please ensure all relevant data has been downloaded from Zenodo (10.5281/zenodo.11038446). Please reference the ReadMe file to sort data into proper folders in the GitHub directory. \n",
    "__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c476d10-5e9a-4165-85f0-ab72b508feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b1848-b367-47fa-b768-ab48500d8304",
   "metadata": {},
   "source": [
    "## Taxonomy Ranks\n",
    "Define the taxonomy ranks to collapse on for all reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2798b6-4fdc-40f7-ac24-6c0bc7979d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_on=[\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eaf555-08eb-4b9b-812a-a096323b566a",
   "metadata": {},
   "source": [
    "## Nasopharyx Samples\n",
    "We'll start with the nasopharynx samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0792a-c91e-4d25-989c-a6de72d212ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize dataframe \n",
    "res = pd.DataFrame()\n",
    "\n",
    "# collect list of NP studies\n",
    "manifest_NP = pd.read_csv('../data/NP/NP_manifest.csv',index_col= 0, header = None)\n",
    "\n",
    "for file_name in manifest_NP.index:\n",
    "    \n",
    "    # pull out feature tables with total reads\n",
    "    ab = qiime_to_dataframe(feature_table=\"../data/NP/\"+file_name+\"_table.qza\",\n",
    "                        taxonomy=\"../data/NP/\"+file_name+\"_taxonomy.qza\", \n",
    "                        collapse_on=collapse_on) \n",
    "    \n",
    "    # merge with metadata\n",
    "    meta = pd.read_csv('../data/NP/'+file_name+'_metadata.tsv', sep=\"\\t\")\n",
    "    meta.rename(columns={meta.columns[0]: \"sample_id\"}, inplace=True)\n",
    "    ab = pd.merge(ab, meta, on=\"sample_id\")\n",
    "    \n",
    "    # identify URT site\n",
    "    ab['URT'] = 'NP'\n",
    "    \n",
    "    # identify study name\n",
    "    ab['study'] = file_name\n",
    "    \n",
    "    # concatenate with original dataframe\n",
    "    res = pd.concat([res,ab])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac8ebb-7154-4182-93c1-94e04633db83",
   "metadata": {},
   "source": [
    "## Oropharynx Samples\n",
    "Next we'll add the oropharynx samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c1f82-db25-4dbb-ac99-325543e56f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect list of OP studies \n",
    "manifest_OP = pd.read_csv('../data/OP/OP_manifest.csv',index_col= 0, header = None)\n",
    "\n",
    "for file_name in manifest_OP.index:\n",
    "    \n",
    "    # pull out feature tables with total reads\n",
    "    ab = qiime_to_dataframe(feature_table=\"../data/OP/\"+file_name+\"_table.qza\",\n",
    "                        taxonomy=\"../data/OP/\"+file_name+\"_taxonomy.qza\", \n",
    "                        collapse_on=collapse_on) \n",
    "    \n",
    "    # merge with metadata\n",
    "    meta = pd.read_csv('../data/OP/'+file_name+'_metadata.tsv', sep=\"\\t\")\n",
    "    meta.rename(columns={meta.columns[0]: \"sample_id\"}, inplace=True)\n",
    "    ab = pd.merge(ab, meta, on=\"sample_id\")\n",
    "    \n",
    "    # identify URT area\n",
    "    ab['URT'] = 'OP'\n",
    "    \n",
    "    # identify study name\n",
    "    ab['study'] = file_name\n",
    "    \n",
    "    # concatenate with original dataframe\n",
    "    res = pd.concat([res,ab])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115927b-852e-452b-aaa2-6ef7d334aa76",
   "metadata": {},
   "source": [
    "## Format Table\n",
    "Now we'll format the table, calculate the centered-log ratio for each read, and add more metadata.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f370a-f454-4418-bd1e-f4bd36f555fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop identified reads or none bacterial reads\n",
    "res = res.dropna(subset = ['genus'])\n",
    "res = res[~(res.genus.str.contains('None'))&~(res.genus.str.contains('uncultured'))&\n",
    "          ~(res.genus.str.contains('Chloroplast'))&~(res.family.str.contains('Mitochondria'))]\n",
    "\n",
    "# centered log-ratio transformation and filtering\n",
    "res = clr(filter_taxa(res, min_reads=2, min_prevalence=0.05)) \n",
    "\n",
    "# add metadata pertaining to studies \n",
    "studies = pd.read_csv('../data/studies.csv',header = None, index_col = 0)\n",
    "res['disease'] = res['study'].map(studies[2].to_dict())\n",
    "res['authors'] = res['study'].map(studies[1].to_dict())\n",
    "res['study'] = res['authors']+', '+res['URT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7281e04-7854-443c-9fee-6d267988cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../data/merged_table.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
